
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=cp1252" />
    <title>ROC Analysis</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="next" title="Test &amp; Score" href="testandscore.html" />
    <link rel="prev" title="Predictions" href="predictions.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="roc-analysis">
<h1>ROC Analysis</h1>
<p>Plots a true positive rate against a false positive rate of a test.</p>
<dl class="docutils">
<dt>Inputs</dt>
<dd><dl class="first last docutils">
<dt>Evaluation Results</dt>
<dd>results of testing classification algorithms</dd>
</dl>
</dd>
</dl>
<p>The widget shows ROC curves for the tested models and the corresponding
convex hull. It serves as a mean of comparison between classification
models. The curve plots a false positive rate on an x-axis
(1-specificity; probability that target=1 when true value=0) against a
true positive rate on a y-axis (sensitivity; probability that target=1
when true value=1). The closer the curve follows the left-hand border
and then the top border of the ROC space, the more accurate the
classifier. Given the costs of false positives and false negatives, the
widget can also determine the optimal classifier and threshold.</p>
<div class="figure">
<img alt="../../_images/ROCAnalysis-basic-stamped.png" src="../../_images/ROCAnalysis-basic-stamped.png" />
</div>
<ol class="arabic">
<li><p class="first">Choose the desired <em>Target Class</em>. The default class is chosen
alphabetically.</p>
</li>
<li><p class="first">If test results contain more than one classifier, the user can choose
which curves she or he wants to see plotted. Click on a classifier to
select or deselect it.</p>
</li>
<li><p class="first">When the data comes from multiple iterations of training and testing,
such as k-fold cross validation, the results can be (and usually are)
averaged.</p>
<div class="figure">
<img alt="../../_images/ROC-Comparison.png" src="../../_images/ROC-Comparison.png" />
</div>
<p>The averaging options are:</p>
<ul class="simple">
<li><strong>Merge predictions from folds</strong> (top left), which treats all the test data as if they came from a single iteration</li>
<li><strong>Mean TP rate</strong> (top right) averages the curves vertically, showing the corresponding confidence intervals</li>
<li><strong>Mean TP and FP at threshold</strong> (bottom left) traverses over threshold, averages the positions of curves and shows horizontal and vertical confidence intervals</li>
<li><strong>Show individual curves</strong> (bottom right) does not average but prints all the curves instead</li>
</ul>
</li>
<li><p class="first">Option <em>Show convex ROC curves</em> refers to convex curves over each
individual classifier (the thin lines positioned over curves). <em>Show
ROC convex hull</em> plots a convex hull combining all classifiers (the
gray area below the curves). Plotting both types of convex curves
makes sense since selecting a threshold in a concave part of the
curve cannot yield optimal results, disregarding the cost matrix.
Besides, it is possible to reach any point on the convex curve by
combining the classifiers represented by the points on the border of
the concave region.</p>
<div class="figure">
<img alt="../../_images/ROCAnalysis-AUC.png" src="../../_images/ROCAnalysis-AUC.png" />
</div>
<p>The diagonal dotted line represents the behaviour of a random
classifier. The full diagonal line represents iso-performance. A black
“<em>A</em>” symbol at the bottom of the graph proportionally readjusts the
graph.</p>
</li>
<li><p class="first">The final box is dedicated to the analysis of the curve. The user can
specify the cost of false positives (FP) and false negatives (FN),
and the prior target class probability.</p>
<p><em>Default threshold (0.5) point</em> shows the point on the ROC curve
achieved by the classifier if it predicts the target class if its
probability equals or exceeds 0.5.</p>
<p><em>Show performance line</em> shows iso-performance in the ROC space so that
all the points on the line give the same profit/loss. The line further
to the upper left is better than the one down and right. The direction
of the line depends upon costs and probabilities. This gives a recipe
for depicting the optimal threshold for the given costs: this is the
point where the tangent with the given inclination touches the curve and
it is marked in the plot. If we push the iso-performance higher or more
to the left, the points on the iso-performance line cannot be reached by
the learner. Going down or to the right, decreases the performance.</p>
<p>The widget allows setting the costs from 1 to 1000. Units are not
important, as are not the magnitudes. What matters is the relation
between the two costs, so setting them to 100 and 200 will give the same
result as 400 and 800.</p>
<div class="figure">
<img alt="../../_images/ROCAnalysis-Plain.png" src="../../_images/ROCAnalysis-Plain.png" />
</div>
<p>Defaults: both costs equal (500), Prior target class probability 50%
(from the data).</p>
<div class="figure">
<img alt="../../_images/ROCAnalysis.png" src="../../_images/ROCAnalysis.png" />
</div>
<p>False positive cost: 830, False negative cost 650, Prior target class
probability 73%.</p>
</li>
<li><p class="first">Press <em>Save Image</em> if you want to save the created image
to your computer in a .svg or .png format.</p>
</li>
<li><p class="first">Produce a report.</p>
</li>
</ol>
<div class="section" id="example">
<h2>Example</h2>
<p>At the moment, the only widget which gives the right type of signal needed by the <strong>ROC Analysis</strong> is <a class="reference internal" href="testandscore.html"><span class="doc">Test&amp;Score</span></a>. Below, we compare two classifiers, namely <a class="reference internal" href="../model/tree.html"><span class="doc">Tree</span></a> and <a class="reference internal" href="../model/naivebayes.html"><span class="doc">Naive Bayes</span></a>, in <strong>Test&amp;Score</strong> and then compare their performance in <strong>ROC Analysis</strong>, <a class="reference internal" href="liftcurve.html"><span class="doc">Life Curve</span></a> and <a class="reference internal" href="calibrationplot.html"><span class="doc">Calibration Plot</span></a>.</p>
<div class="figure">
<img alt="../../_images/ROCAnalysis-example.png" src="../../_images/ROCAnalysis-example.png" />
</div>
</div>
</div>


          </div>
          
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2015, Orange Data Mining.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.11</a>
      
      |
      <a href="../../_sources/widgets/evaluation/rocanalysis.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>