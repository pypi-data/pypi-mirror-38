# ultimate
A very simpe neural network implemention for python

## Installation
pip install ultimate

## Why Ultimate?
+ Super tiny and super easy
+ Support feature importance
+ Support missing values
+ Support am2/a2m2/am2l/a2m2l activation functions
+ Support hardmse/hardmax loss functions

## How To Use?
<pre>
from ultimate.mlp import MLP
  
mlp = MLP(
  mi=0,                        
  dtype='float64',            
  activation=[],              # am2/a2m2/am2l/a2m2l
  layer_size=[],
  input_type='pointwise',
  loss_type='mse',            # mse/softmax/hardmse/hardmax
  output_range=[0, 1],
  output_shrink=0.001, 
  importance_mul=0.001,
  leaky=-0.001,
  dropout=0,
  bias_rate=[0.005], 
  weight_rate=[],
  regularization=1
)

mlp.train(
  in_arr, 
  target_arr,
  epoch_train=5, 
  epoch_decay=1, 
  iteration_log=100,
  rate_init=0.06, 
  rate_decay=0.9,
  importance_out=False,
  loss_mul=0.001, 
  verbose=1, 
  shuffle=True
)

mlp.predict(
  in_arr, 
  out_arr=None, 
  verbose=0, 
  iteration_log=100
)
</pre>

## Examples
+ [Feature Importance](https://www.kaggle.com/anycode/feature-importance-using-nn)
+ [Image Regression](https://www.kaggle.com/anycode/image-regression)
+ [Iris Classification](https://www.kaggle.com/anycode/image-regression)
+ [MNIST Recognition](https://www.kaggle.com/anycode/mnist-recognition)

