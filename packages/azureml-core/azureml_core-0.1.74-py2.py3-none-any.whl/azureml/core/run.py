# ---------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# ---------------------------------------------------------

"""
**Run** provides a class to conveniently read and record experiment metrics and artifacts.

"""
import logging
import os
import re

from collections import defaultdict
from six import raise_from
from inspect import isgeneratorfunction
from types import GeneratorType

from azureml.exceptions import RunEnvironmentException
from azureml.core.authentication import AzureMlTokenAuthentication
from azureml._run_impl.run_base import _RunBase
from azureml._history.utils.constants import OUTPUTS_DIR
from azureml._restclient.constants import BASE_RUN_SOURCE, RUN_ORIGIN, SDK_TARGET
from azureml._restclient.utils import camel_case_transformer

module_logger = logging.getLogger(__name__)


class Run(_RunBase):
    """
    The base class for all experiment runs.

    .. remarks::

        A *run* represents a single trial of an experiment.  A run is the object used to monitor the
        asynchronous execution of a trial, log metrics and store output of the trial,
        and to analyze results and access artifacts generated by the trial.

        Run is used inside of your experimentation code to log metrics and artifacts to the Run History service.

        Run is used  outside of your experiments monitor progress and to query and analyze
        the metrics and results that were generated.

        Functionality includes:

        *  Storing and retrieving metrics and data
        *  Uploading and downloading files
        *  Using tags as well as the child hierarchy for easy lookup of past runs
        *  Registering stored model files as model's that can be operationalized
        *  Storing, modifying and retrieving properties of a run
        *  Loading the current run from a remote environment with Run.get_context()
        *  Efficiently snapshotting a file or directory for reproducibility

        This class works with the :class:`azureml.core.Experiment` and is used in these scenarios

        #. Creating a run by executing code using :func:`azureml.core.Experiment.submit`
        #. Creating a run interactivly in a notebook using :func:`azureml.core.Experiment.start_logging`
        #. Logging metrics and uploading artifacts in your experiment code using :func:`log` and other methods
        #. Reading metrics and downloading artifacts when analyzing experimental results using :func:`get_metrics`
           and other methods

        To submit a run, create a configuration object that describes how the experiment is run.
        These objects include:

        * :class:`azureml.core.ScriptRunConfig`
        * :class:`azureml.train.hyperdrive.HyperdriveRunConfig`
        * :class:`azureml.train.automl.AutoMLConfig`
        * :class:`azureml.pipeline.core.PipelineRun`
        * :class:`azureml.pipeline.core.PublishedPipeline`


    :param experiment: The experiment.
    :type experiment: azureml.core.Experiment
    :param run_id: The run id for the run.
    :type run_id: str
    :param outputs: The outputs to be tracked
    :type outputs: str
    :param _run_dto:
    :type _run_dto: azureml._restclient.models.run_dto.RunDto
    :param kwargs:
    """

    _RUNSOURCE_PROPERTY = BASE_RUN_SOURCE
    _run_source_initializers = {
        # 'experimentrun': ExperimentRun.from_dto
        # TODO: Need to refactor ExperimentRun for that
    }

    def __init__(self, experiment, run_id, outputs=None, _run_dto=None, **kwargs):
        """
        Initialize the Run object.

        :param experiment: The containing experiment.
        :type experiment: azureml.core.Experiment
        :param run_id: The run id for the run.
        :type run_id: str
        :param outputs: The outputs to be tracked
        :type outputs:
        :param _run_dto:
        :type _run_dto: azureml._restclient.models.run_dto.RunDto
        :param kwargs:
        :type kwargs: dict
        """
        super(Run, self).__init__(experiment, run_id,
                                  outputs=outputs, _run_dto=_run_dto, **kwargs)

    @staticmethod
    def clean_all(project_object, run_config):
        """
        DEPRECATED
        Remove files corresponding to all azureml runs on the target specified by run_config.

        :param project_object: The project object.
        :type project_object: azureml.core.project.Project
        :param run_config: This can be a run configuration name as string, or a RunConfiguration object.
        :type run_config: str or azureml.core.runconfig.RunConfiguration
        :return: List of files deleted.
        :rtype: list

        """
        from azureml._execution import _commands
        run_config_object = project_object._get_run_config_object(run_config)
        return _commands.clean(project_object, run_config_object, all=True)

    @staticmethod
    def _dto_to_run(experiment, run_dto, outputs=None,
                    _child_auth=None, **kwargs):
        """
        Create a Run object from the service representation.

        :param experiment: The experiment object for the run.
        :type experiment: azureml.core.Experiment
        :param run_dto:
        :type run_dto: azureml._restclient.models.run_dto.RunDto
        :param outputs: Outputs directory to be tracked
        :type outputs: str
        :param _child_auth:
        :type _child_auth: azureml.core.authentication.AzureMlTokenAuthentication:
        :param kwargs:
        :type kwargs: dict
        :return: Returns the Run object
        :rtype: Run

        """
        from .experiment import Experiment
        from .workspace import Workspace
        # TODO remove when transitioning to new api
        if type(run_dto) is not dict:
            run_dto = run_dto.__dict__

        workspace = experiment.workspace
        # TODO change run token auth to allow root to auth children
        # If false, current auth works for child and is passed through
        child_auth = _child_auth if _child_auth is not None else workspace._auth_object

        child_workspace = Workspace(workspace.subscription_id,
                                    workspace.resource_group,
                                    workspace.name,
                                    _location=workspace.location,
                                    _disable_service_check=True,
                                    auth=child_auth)

        experiment = Experiment(child_workspace, experiment.name)
        run_id = run_dto["run_id"]
        child = Run(experiment, run_id, outputs=outputs, _run_dto=run_dto, **kwargs)
        return child

    @classmethod
    def _load_scope(cls):
        """
        Load the current context from the environment.

        :return: experiment, run_id, url
        :rtype: azureml.core.Experiment, str, str
        """
        from .authentication import AzureMlTokenAuthentication
        from .experiment import Experiment
        from .workspace import Workspace

        try:
            # Load authentication scope environment variables
            subscription_id = os.environ['AZUREML_ARM_SUBSCRIPTION']
            run_id = os.environ["AZUREML_RUN_ID"]
            resource_group = os.environ["AZUREML_ARM_RESOURCEGROUP"]
            workspace_name = os.environ["AZUREML_ARM_WORKSPACE_NAME"]
            experiment_name = os.environ["AZUREML_ARM_PROJECT_NAME"]

            # Initialize an AMLToken auth, authorized for the current run
            token = os.environ['AZUREML_RUN_TOKEN']

            url = os.environ["AZUREML_SERVICE_ENDPOINT"]
            location_from_url_regex_match = re.compile(r"//(.*?)\.").search(url)
            location = location_from_url_regex_match.group(1) if location_from_url_regex_match else None
        except KeyError as key_error:
            raise_from(RunEnvironmentException(), key_error)
        else:
            auth = AzureMlTokenAuthentication(token)
            # Disabling service check, as this is in remote context and we don't have an arm token
            # to check arm if the workspace exists or not.
            workspace = Workspace(subscription_id, resource_group, workspace_name,
                                  auth=auth, _location=location, _disable_service_check=True)

            experiment = Experiment(workspace, experiment_name)

            return experiment, run_id, url

    @classmethod
    def get_context(cls, **kwargs):
        """
        Returns the run that was created by an experiment submission.  This method is used inside experiment code.

        .. remarks::

            .. code-block:: python

                run = Run.get_context()
                ...
                run.log_metric("Accuracy")


        :return: The submitted run.
        :rtype: azureml.core.run.Run
        """
        experiment, run_id, url = cls._load_scope()

        # Querying for the run instead of initializing to load current state
        return _SubmittedRun(experiment, run_id, _cluster_url=url, **kwargs)

    @classmethod
    def get_submitted_run(cls, **kwargs):
        """
        DEPRECATED: use :func:`get_context`
        Get the submitted run for this experiment.

        :return: The submitted run
        :rtype: azureml.core.run.Run
        """
        module_logger.warning("Deprecated, use Run.get_context() instead")
        return cls.get_context(**kwargs)

    @staticmethod
    def _add_runsource_factory(runsource_key, run_factory):
        """
        :param runsource_key:
        :type runsource_key: str
        :param run_factory:
        :type run_factory: str
        """
        module_logger.warning("This function is deprecated, please use Run.add_type_provider instead")
        Run.add_type_provider(runsource_key, run_factory)

    @staticmethod
    def add_type_provider(runtype, run_factory):
        """
        :param runtype:
        :type runtype: str
        :param run_factory:
        :type run_factory: str
        """
        if Run._run_source_initializers.get(runtype, None) is not None:
            raise ValueError("RunType {0} already has a factory, can't add another".format(runtype))

        # TODO: Validate signature of the factory if possible via the code object
        module_logger.debug("Adding new factory {0} for run source {1}".format(run_factory, runtype))
        Run._run_source_initializers[runtype] = run_factory

    @staticmethod
    def _rehydrate_runs(experiment, run_dtos):
        """
        :param experiment:
        :type experiment: azureml.core.Experiment
        :param run_dtos:
        :type run_dtos: azureml._restclient.models.run_dto.RunDto
        """
        module_logger.debug("Available factories for run types {0}".format(Run._run_source_initializers))
        for run_dto in run_dtos:
            run_id = run_dto.run_id

            # TODO: Run source is around for backward compatibility. Delete after PuP
            run_properties = getattr(run_dto, "properties", {})
            run_source = run_properties.get(Run._RUNSOURCE_PROPERTY, 'None')
            runtype = run_dto.run_type if run_dto.run_type is not None else run_source

            module_logger.debug("Initializing Run {0} from type {1}".format(run_id, runtype))

            factory = Run._run_source_initializers.get(runtype, Run._dto_to_run)
            yield factory(experiment, run_dto)

    @staticmethod
    def list(experiment, type=None, tags=None, properties=None, status=None, _rehydrate_runs=True):
        """
        Get a list of runs in an experiment specified by optional filters.

        :param experiment: The experiment.
        :type experiment: azureml.core.Experiment
        :param rehydrate_runs:
        :type rehydrate_runs: bool
        :param type: If specified, returns runs matching specified type
        :type type: str
        :param tags:  If specified, returns runs matching specified *"tag"* or {*"tag"*: *"value"*}
        :type tags: str or dict
        :param properties: If specified, returns runs matching specified *"property"* or {*"property"*: *"value"*}
        :type properties: str or dict
        :param status: If specified, returns runs with status specified *"status"*
        :type status: str
        :param _rehydrate_runs:
        :type _rehydrate_runs: bool
        :return: list of azureml.core.run.Run
        :rtype: list[azureml.core.run.Run]

        """
        from azureml._run_impl.run_client import RunClient

        run_dtos = RunClient.get_runs(experiment, runtype=type, tags=tags, properties=properties, status=status)

        module_logger.debug("Rehydrating runs on enumerate: {0}".format(_rehydrate_runs))
        if _rehydrate_runs:
            return Run._rehydrate_runs(experiment, run_dtos)
        else:
            return (Run._dto_to_run(experiment, run_dto) for run_dto in run_dtos)

    @staticmethod
    def _start_logging(experiment, name=None, run_id=None,
                       outputs=None, **kwargs):
        """
        Create and start a new run for the workspace and experiment name.

        :param experiment: The experiment.
        :type experiment: azureml.core.Experiment
        :param name: Optional name for the run
        :type name: str
        :param run_id: Optional run_id for the run, otherwise uses default
        :type run_id: str
        :param outputs: Optional outputs directory to track
        :type outputs: str
        :return: Return a run.
        :rtype: azureml.core.run.Run
        :param kwargs:
        """
        outputs = outputs if outputs else OUTPUTS_DIR
        run = Run._create(experiment, name=name,
                          run_id=run_id, outputs=outputs, **kwargs)
        run._client.start()
        return run

    @staticmethod
    def _create(experiment, name=None, run_id=None,
                outputs=None, **kwargs):
        """
        Create a new run for the workspace and experiment name.

        :param experiment: The experiment.
        :type experiment: azureml.core.Experiment
        :param name: Optional name for the run
        :type name: str
        :param run_id: Optional run_id for the run, otherwise uses default
        :type run_id: str
        :param outputs: Optional outputs directory to track
        :type outputs: str
        :return: Return a run.
        :rtype: azureml.core.run.Run
        :param kwargs:
        """
        from azureml._run_impl.run_client import RunClient
        run_dto = RunClient.create_run(experiment, name=name, run_id=run_id)
        return Run._dto_to_run(experiment, run_dto, outputs=outputs, **kwargs)

    @property
    def id(self):
        """
        The id of the run - an identifier unique across the containing experiment

        :return: the run id
        :rtype: str
        """
        return self._run_id

    @property
    def type(self):
        """
        The Run type, indicated in how the run was created or configured

        :return: the run type
        :rtype: str
        """
        return self._runtype

    @property
    def number(self):
        """
        Return the Run Number - a monotonically increasing number representing the order of runs
        within an experiment.

        :return: The run number.
        :rtype: int
        """
        self._logger.warning("Unstable, may be removed in the future")
        return self._run_number

    def get_status(self):
        """
        Get the run's current state.

        :return: Return the status
        :rtype: str
        """
        if self._latest_status in ["Completed", "Failed", "Canceled"]:
            return self._latest_status
        else:
            return self._client.get_status()

    def get_details(self):
        """
        Get the definition, status information and other details of the run.

        :return: Return the details for the run
        :rtype: dict[str]
        """
        return self._client.get_runstatus().as_dict(key_transformer=camel_case_transformer)

    def get_children(self, recursive=False, tags=None, properties=None, type=None, status=None, _rehydrate_runs=True):
        """
        Get all children for the current run selected by specified filters.

        :param rehydrate_runs:
        :type rehydrate_runs: bool
        :param recursive: Indicates whether to recurse through all descendants.
        :type recursive: bool
        :param type: If specified, returns runs matching specified type
        :type type: str
        :param tags:  If specified, returns runs matching specified *"tag"* or {*"tag"*: *"value"*}
        :type tags: str or dict
        :param properties: If specified, returns runs matching specified *"property"* or {*"property"*: *"value"*}
        :type properties: str or dict
        :param status: If specified, returns runs with status specified *"status"*
        :type status: str
        :param _rehydrate_runs:
        :type _rehydrate_runs: bool
        :return: A list of azureml.core.run.Run
        :rtype: list
        """
        children = self._client.get_descendants(
            root_run_id=self._root_run_id,
            recursive=recursive,
            tags=tags,
            properties=properties,
            runtype=type,
            status=status)

        self._logger.debug("Rehydrating runs on enumerate: {0}".format(_rehydrate_runs))
        if _rehydrate_runs:
            return Run._rehydrate_runs(self.experiment, children)
        else:
            return (Run._dto_to_run(self.experiment, child) for child in children)

    def get_metrics(self, name=None, recursive=False, run_type=None):
        """
        Retrieve the metrics logged to the run.

        :param name:
        :type name: str
        :param recursive:
        :type recursive: bool
        :param run_type:
        :type run_type: str
        :return: A dictionary containing the users metrics.
        :rtype: dict
        """
        if name is not None:
            raise NotImplementedError("Cannot filter on metric name yet")

        if recursive:
            # TODO: No better way?
            descendant_ids = [
                child.run_id for child in self._client.get_descendants(
                    root_run_id=self._root_run_id,
                    recursive=True,
                    runtype=run_type)
            ]
            metrics = self._client._client.get_metrics_by_run_ids(run_ids=descendant_ids + [self.id])
            # TODO: changing return structure based on parameter is awkward
            # TODO: Refactor metrics client to be a bit more composable
            metrics_dtos_by_run = defaultdict(list)
            for dto in metrics:
                metrics_dtos_by_run[dto.run_id].append(dto)
            return {
                runid: self._client.metrics.dto_to_metrics_dict(metric_dto_list)
                for runid, metric_dto_list in metrics_dtos_by_run.items()
            }
        else:
            return self._client.metrics.get_all(self.id)

    @property
    def experiment(self):
        """
        The experiment containing the run.

        :return: Retrieves the experiment corresponding to the run.
        :rtype: azureml.core.Experiment
        """
        return self._experiment

    def complete(self):
        """
        Mark the run as completed.  This is typically used in interactive notebook scenarios.
        """
        self._client.complete()

    def fail(self):
        """
        Mark the run as failed.
        """
        self._client.fail()

    def __enter__(self):
        """
        Initialize features related to ouputs tracking and status updates for the run."
        :return:
        :rtype: Run
        """
        super(Run, self).__enter__()
        return self

    def __exit__(self, exit_type, value, traceback):
        """
        Close tracking and collect outputs.
        :param exit_type:
        :type exit_type:
        :param value:
        :type value:
        :param traceback:
        :type traceback:
        :return:
        :rtype: Run
        """
        return super(Run, self).__exit__(exit_type, value, traceback)

    def child_run(self, name=None, run_id=None, outputs=None):
        """
        Create a child run.

        .. remarks::

            This is used to isolate part of a run into a subsection.  This can be done for
            identifiable "parts" of a run that are interesting to seperate, or to capture
            independent metrics across an interation of a subprocess.

            If an output directory is set for the child run, the contents of that directory will be
            uploaded to the child run record when the child is completed.

        :param name: Optional name for the child, typically specified for a "part"
        :type name: str
        :param run_id: Optional run_id for the child, otherwise auto-generated.  Typically not set
        :type run_id: str
        :param outputs: Optional outputs directory to track for the child
        :type outputs: str
        :return: the child run
        :rtype: azureml.core.run.Run
        """
        auth = self.experiment.workspace._auth_object
        child_dto = self._client.create_child_run(self._run_dto.get("name"),
                                                  self._run_dto.get("target", SDK_TARGET),
                                                  child_name=name,
                                                  run_id=run_id)
        if isinstance(auth, AzureMlTokenAuthentication):
            auth = AzureMlTokenAuthentication(child_dto["token"])

        child = Run._dto_to_run(self.experiment, child_dto, _child_auth=auth, outputs=outputs,
                                _worker_pool=self._client.worker_pool, _parent_logger=self._logger)
        child._client.start()
        return child

    def tag(self, key, value=None):
        """
        Tag the run with a string key and optional string value.

        :param key:
        :type key: str
        :param value:
        :type value: str
        """
        self._client.set_tag(key, value)

    def set_tags(self, tags):
        """
        Add a set of tags to the run.

        :param tags: The tags stored in the run object
        :type tags: dict[str] = str
        """
        self._client.set_tags(tags)

    def get_tags(self):
        """
        Get the set of mutable tags on the run.

        :return: The tags stored on the run object
        :rtype: dict
        """
        return self._client.get_tags()

    def add_properties(self, properties):
        """
        Add hidden properties to the run.

        :param properties: The hidden properties stored in the run object
        :type properties: dict
        """
        self._client.add_properties(properties)

    def get_properties(self):
        """
        Get the properties of the run.

        .. remarks::

            Properties include immutable system-generated information such as
            duration, date of execution, user, etc.

        :return: The properties of the run
        :rtype: dict
        """
        return self._client.get_properties()

    def log(self, name, value, description=""):
        """
        Log a metric value to the run with the given name.

        .. remarks::

            Logging a metric to a run causes that metric to be stored in
            the run record in the experiment.  You can log the same metric
            multiple times within a run, the result being considered a vector
            of that metric.

            .. code-block: python

                run = experiment.start_logging()
                run.log('Accuracy', (tp + tn) / (p + n))
                run.log('Precision', tp / (tp + fp))
                run.log('Recall', tp / (tp + fn))

        :param name: The name of metric
        :type name: str
        :param value: The name of metric
        :type value: any, The value to be posted to the service
        :param description: An optional metric description
        :type description: str
        """
        # python2/3 compatible check for range, range is not a python2 type
        is_range = isinstance(value, type(range(0)))
        if any([isinstance(value, list),
                is_range,
                isgeneratorfunction(value),
                isinstance(value, GeneratorType)]):
            module_logger.warning("Deprecated, run.log does not support "
                                  "list type. Use run.log_list instead")
            return self._client.metrics.log_list(self.id, name, value, description=description)
        else:
            return self._client.metrics.log_scalar(self.id, name, value, description=description)

    def log_list(self, name, value, description=""):
        """
        Log a list metric value to the run with the given name.

        :param name: The name of metric
        :type name: str
        :param value: The name of metric
        :type value: list, The list of scalars to be posted to the service
        :param description: An optional metric description
        :type description: str
        """
        return self._client.metrics.log_list(self.id, name, value, description)

    def log_row(self, name, description=None, **kwargs):
        """
        Log a row metric to the run with the given name.

        .. remarks::

            Using *log_row* creates a table metric with columns as described in kwargs.  Each named
            parameter generates a column with the value specified.  *log_row* can be
            be called once to log an aribitrary tuple, or multiple times in a loop to generate
            a complete table.

            .. code-block:: python

                citrus = ['orange', 'lemon', 'lime']
                sizes = [ 10, 7, 3]
                for index in range(len(citrus)):
                    run.log_row("citrus", fruit = citrus[index], size=sizes[index])

        :param name: The name of metric
        :type name: str
        :param description: An optional metric description
        :type description: str
        :param kwargs:
        """
        return self._client.metrics.log_row(self.id, name, value=kwargs, description=description)

    def log_table(self, name, value, description=""):
        """
        Log a table metric to the run with the given name.

        :param name: The name of metric
        :type name: str
        :param value: The table value of the metric
        :type value: str
        :type value dict: The dictionary of str to columns to be posted to the service
        :param description: An optional metric description
        :type description: str
        """
        return self._client.metrics.log_table(self.id, name, value, description)

    def log_image(self, name, path=None, plot=None):
        """
        Log an image metric to the run record.

        .. remarks::

            Use log_image to log an image file or a matplotlib plot to the run. These images will
            be visible and comparable in the run record.

        :param name: The name of metric
        :type name: str
        :param path: The path or stream of the image
        :type path: str
        :param plot: The plot to log as an image
        :type plot: matplotlib.pyplot
        """
        return self._client.log_image(name, path=path, plot=plot)

    def upload_file(self, name, path_or_stream):
        """
        Upload a file to the run record.

        .. remarks::

            .. note::

                Runs automatically capture file in the specified output directory, which defaults
                to "./outputs" for most run types.  Use upload_file only when additional files need
                to be uploaded or an output directory is not specified.

        :param name: The name of the file to be uploaded
        :type name: str
        :param path_or_stream: The relative local path or stream to the file to upload
        :type path_or_stream: str
        :return:
        :rtype: azure.storage.blob.models.ResourceProperties
        """
        return self._client.artifacts.upload_artifact(path_or_stream, RUN_ORIGIN, self.id, name)

    def get_file_names(self):
        """
        List the files that are stored in association with the run.

        :return: The list of paths for existing artifacts
        :rtype: list[str]
        """
        return list(self._client.artifacts.get_file_paths(RUN_ORIGIN, self.id))

    def download_file(self, name, output_file_path=None):
        """
        Download an associated file from storage.

        :param name: The name of the artifact to be downloaded
        :type name: str
        :param output_file_path: The local path where to store the artifact
        :type output_file_path: str
        """
        base_file_name = os.path.basename(name)  # save outputs/filename.txt as filename.txt
        if output_file_path is None:
            self._logger.debug("output_file_path for download_file was not set.")
            output_file_path = base_file_name
        elif os.path.isdir(output_file_path):
            self._logger.debug("output_file_path for download_file is a directory.")
            output_file_path = os.path.join(output_file_path, base_file_name)
        else:
            self._logger.debug("output_file_path for download_file is not a directory.")

        self._client.artifacts.download_artifact(RUN_ORIGIN, self.id, name, output_file_path)

    def take_snapshot(self, file_or_folder_path):
        """
        Save a snapshot of the inputted file or folder.

        .. remarks::

            Snapshots are intended to be the *source code* used to execute the experiment run.
            These are stored with the run so that the run trial can be replicated in the future.

            .. note::

                Snapshots are automatically taken when :func:azureml.core.Experiment.submit is called.
                Typically take_snapshot is only required for interactive (notebook) runs.

        :param file_or_folder_path: The file or folder containing the run source code.
        :type file_or_folder_path: str
        :return: Returns the snapshot id
        :rtype: str
        """
        from azureml._base_sdk_common.project_context import create_project_context
        from azureml._base_sdk_common.create_snapshot import create_snapshot
        workspace = self.experiment.workspace
        project_context = create_project_context(workspace._auth_object,
                                                 subscription_id=workspace.subscription_id,
                                                 resource_group=workspace.resource_group,
                                                 workspace=workspace.name,
                                                 project_name=self.experiment.name)
        snapshot_id = create_snapshot(file_or_folder_path, project_context)
        self._snapshot_ids.append(snapshot_id)
        return snapshot_id

    def snapshot_restore(self, snapshot_id=None, path=None):
        """
        DEPRECATED: use restore_snapshot
        :param snapshot_id: The snapshot id to restore, the latest if not specified.
        :type snapshot_id: str
        :param path: The path where the downloaded zip is saved.
        :type path: str
        :return: The path.
        :rtype: str
        """
        module_logger.warning("Deprecated, Use run.restore_snapshot instead")

        return self.restore_snapshot(snapshot_id, path)

    def restore_snapshot(self, snapshot_id=None, path=None):
        """
        Restores a snapshot as a zip file. Returns the path to the zip.

        :param snapshot_id: The snapshot id to restore, the latest if not specified.
        :type snapshot_id: str
        :param path: The path where the downloaded zip is saved.
        :type path: str
        :return: The path.
        :rtype: str
        """
        from azureml._base_sdk_common.project_context import create_project_context
        from azureml._base_sdk_common.restore_snapshot import RestoreSnapshot
        workspace = self.experiment.workspace
        if snapshot_id is None:
            snapshot_id = self.get_snapshot_id()

        project_context = create_project_context(workspace._auth_object,
                                                 subscription_id=workspace.subscription_id,
                                                 resource_group=workspace.resource_group,
                                                 workspace=workspace.name,
                                                 project_name=self.experiment.name)
        restore = RestoreSnapshot(project_context)
        path = restore.restore_snapshot(snapshot_id, path)
        return path

    def get_snapshot_id(self):
        """
        Get the latest snapshot id.

        :return: The most recent snapshot id.
        :rtype: str
        """
        if not self._snapshot_ids:
            properties = self.get_properties()
            snapshot_id = properties.get("ContentSnapshotId", None)
            self._snapshot_ids.append(snapshot_id)
        latest_snapshot = self._snapshot_ids[-1]
        return latest_snapshot

    def register_model(self, model_name, model_path=None, **kwargs):
        """
        Register a model for operationalization

        .. remarks::

            .. code-block:: python

                model = best_run.register_model(model_name = 'best_model', model_path = 'outputs/model.pkl')

        :param model_name:
        :type model_name: str
        :param model_path: relative cloud path to model from outputs/ dir. When model_path is None, model_name is path.
        :type model_path: str
        :param kwargs:
        :return:
        :rtype: azureml.core.model.Model
        """
        return self._client.register_model(model_name, model_path, **kwargs)


class _SubmittedRun(Run):
    """Run class for remote execution."""

    def complete(self):
        """Override complete since it is not supported for submitted runs."""
        self._logger.warning("complete is not supported for submitted runs.")

    def fail(self):
        """Override fail since it is not supported for submitted runs."""
        self._logger.warning("fail is not supported for submitted runs.")

    def __enter__(self):
        """Override __enter__ since it is not supported for submitted runs."""
        self._logger.warning("Submitted runs are not supported context managers.")

    def __exit__(self, *args):
        """
        Override __exit__ since it is not supported for submitted runs.
        :param args:
        """
        self._logger.warning("Submitted runs are not supported context managers.")
