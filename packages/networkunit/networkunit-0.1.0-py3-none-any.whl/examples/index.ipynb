{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An Introduction to NetworkUnit\n",
    "#### with examples of comparing model implementations (C vs. SpiNNaker) and experimental data (monkey L vs. monkey N)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "*navigate through the slides with the spacebar or arrow keys*\n",
    "\n",
    "*or view the Jupyter notebook by clicking the X in the upper left corner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "When considering model simulations and their evaluation, it is important\n",
    "to precisely define the terminology and to be clear about the interpretation\n",
    "of the results in order to judge the validity and the scope of applicability\n",
    "of the model. For all practical purposes, in modeling one should be\n",
    "concerned with its testable correctness relative to the given system\n",
    "of interest, because only this process justifies its use as the basis\n",
    "for analytic reasoning and prediction making.\n",
    "\n",
    "In 1979 the Technical Committee on Model Credibility of the Society\n",
    "of Computer Simulation established a widely recognized description\n",
    "of a model verification and validation environment. We adapt this\n",
    "terminology to the field of neural network modeling \n",
    "([*Trensch et al.* , 2018](#trensch2018); [*Gutzen et al.* , sub.](#gutzen2018)). \n",
    "The validation setup\n",
    "is separated into three basic elements (see figure below).\n",
    "The system of interest can be defined as \"an entity, situation,\n",
    "or system which has been selected for analysis\" ([*Schlesinger et al.* ,1979.](#schlesinger1979)),\n",
    "and constitutes the references against which validations are carried\n",
    "out. When specifying this system of interest it is important to also\n",
    "explicitly define the boundaries in which the modeling is expected\n",
    "to be adequate. The modeling effort itself is separated into the definition\n",
    "of the conceptual model, and its implementation as a computerized\n",
    "model. The conceptual model is an abstract description formed by analysis\n",
    "and observation of the system of interest. In the case of network\n",
    "simulations, the conceptual model takes on the form of a mathematical\n",
    "model describing the dynamics of neurons and the connectivity structure,\n",
    "and other dynamic features of the simulation (e.g., inclusion of neuromodulatory\n",
    "effects). An implementation of the conceptual mathematical model in\n",
    "a computer software or in hardware, on the other hand, results in\n",
    "a computerized, or more concretely for neural simulation, an executable\n",
    "model.\n",
    "\n",
    "The process of evaluating the degree to which the executable model is a correct\n",
    "realization of the mathematical model is termed 'verification'.\n",
    "In contrast, the comparison of the predictions generated by the computerized\n",
    "model to the system of interest considering its intended domain of\n",
    "applicability is the process called 'validation'. Together with\n",
    "the process of 'confirmation', which attributes credibility to the\n",
    "mathematical model as a useful description of the system of interest,\n",
    "these three attributes form a circle that typically receives multiple\n",
    "iterations consisting of improvements of the mathematical model and\n",
    "its implementation as an executable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style='float:left; width:48%; display:inline-block'>\n",
    "    <img src=\"../figures/validation_environment.png\" width=\"100%\" />\n",
    "</div>\n",
    "<div style='float:right; text-align:left; width:48%; display:inline-block'>\n",
    "    <p><b>System of interest:</b> an entity, situation, or system which has been selected for analysis</p><br>\n",
    "    <p><b>Mathematical model:</b> an abstract description formed by analysis and observation of the system of interest.</p><br>\n",
    "    <p><b>Executable model:</b> an implementation of the mathematical model</p><br>\n",
    "    <p><b>Confirmation:</b> attributing credibility to the mathematical model as a useful description of the system of interest.</p><br>\n",
    "    <p><b>Verification:</b> evaluation whether the executable model is a correct realization of the mathematical model</p><br>\n",
    "    <p><b>Validation:</b> a quantitative evaluation of usefulness and accuracy</p><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The NetworkUnit module builds upon the formalized validation scheme of the [SciUnit](https://github.com/scidash/sciunit) package, \n",
    "which enables the validation of *model*s against experimental data (or other models) via *tests*.\n",
    "A test is matched to the model by *capabilities* and quantitatively evaluated by a *score*.\n",
    "The following figure illustrates a typical test design within NetworkUnit. \n",
    "The blue boxes indicate the components of the implementation of the validation test, i.e., \n",
    "classes, class instances, data sets, and parameters. \n",
    "The relation between the boxes are indicated by annotated arrows.The basic functionality is \n",
    "shown by green arrows.  The difference in the test design for comparing against experimental \n",
    "data (validation) and  another  simulation  (substantiation)  is  indicated  by  yellow  and  \n",
    "red  arrows,  respectively.  The  relevant  functionality  of  some  components  for  the  \n",
    "computation  of  test  score  is  indicated  by  pseudo-code.  The  capability  \n",
    "class `ProducesProperty` contains  the  function `calc_property()`. The test `XYTest` has a function \n",
    "`generate_prediction()` which makes use of this capability, inherited by the model class, \n",
    "to generate a model prediction. The initialized test instance `XYTest_paramZ` makes use of its \n",
    "`judge()` function to evaluate this model prediction and compute the score `TestScore`. \n",
    "The `XYTest` can inherit from multiple abstract test classes (`BaseTest`), \n",
    "which is for example used with the `M2MTest` to add the functionality of evaluating multiple model classes. \n",
    "To make the test executable it has to be linked to a ScoreType and all free parameters need to be set \n",
    "(by a `Params` dict) to ensure a reproducible result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style='width:50%; display:block; margin-left:auto; margin-right:auto'>\n",
    "        <img src=\"../figures/NetworkUnit_Flowchart_X2M_M2M.png\" width=\"100%\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So far, we considered a scenario in which a model is compared to experimental\n",
    "observations. However, there are circumstances in which a model is\n",
    "the object of reference. This model could be another implementation\n",
    "of the model under scrutiny, an alternative model, or a different\n",
    "simulation run of the same model. In the following, we explore such\n",
    "validation scenarios, which we collectively term *model-to-model\n",
    "validation*. When using NetworkUnit every test comparing model to \n",
    "experiment (`example_test`) can be transformed to a test comparing \n",
    "two (or more) models by inheritence of the `M2MTest` class.\n",
    "\n",
    "`class example_test_M2M(sciunit.TestM2M, example_test):`\n",
    "\n",
    "One possible scenario is the need to demonstrate the\n",
    "equivalence of alternative implementations of the same model. These\n",
    "implementations could, for example, be realized by different simulation\n",
    "engines, like in our first example by a C simulation and a simulation on the SpiNNaker hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import sciunit\n",
    "import elephant\n",
    "import numpy as np\n",
    "from quantities import ms\n",
    "from neo.core import SpikeTrain\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='ticks')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# How to add NetworkUnit to other projects\n",
    "\n",
    "!git clone https://github.com/INM-6/NetworkUnit.git\n",
    "!cd NetworkUnit/; git fetch; git pull\n",
    "\n",
    "sys.path.insert(0, './NetworkUnit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#sys.path.insert(0, '../') # sys.path.insert(0, 'path/to/networkunit')\n",
    "from networkunit import models, tests, scores, plots, capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Validating a SpiNNaker simulation against a C simulation\n",
    "For this comparison we use a polychronization network model ([*Izhikevich* , 2006](#izhikevich2006)) as it produces a rich repertoir of network dynamics. This model simulated with both a C implementation and an implementation on the neuromorphic SpiNNaker system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The simulation data is available via [a GIN repository](https://web.gin.g-node.org/INM-6/network_validation) from which it can be loaded into the local storage with *git-annex* (or alternatively the gin-client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Clone gin repository \n",
    "!git clone git@gin.g-node.org:/INM-6/network_validation.git\n",
    "\n",
    "# load simulation data\n",
    "os.chdir('./network_validation')\n",
    "!git-annex get ./simulation_data/iteration_III/60s_simulation_runs/*/out_firings_after5h.dat\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a remote server it is only possible to download the data with `wget`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(echo \"C/out_firings_after5h.dat\" && echo \"SpiNNaker/out_firings_after5h.dat\") > download_files.txt\n",
    "!wget -nH -nc -np -r -e robots=off -i download_files.txt -B https://web.gin.g-node.org/INM-6/network_validation/raw/master/simulation_data/iteration_III/60s_simulation_runs/\n",
    "data_path = \"./INM-6/network_validation/raw/master/simulation_data/iteration_III/60s_simulation_runs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The simulation is implemented in a model class\n",
    "The model class should either be able to run the simulation or else load data from a simulation (what we do here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class polychrony_data(models.spiketrain_data):\n",
    "    file_path = '' # to be added in child class\n",
    "    params = {'align_to_0': True,\n",
    "              'filter_inh': True}\n",
    "    \n",
    "    def load(self, file_path, simulator, t_start=0, t_stop=60000, filter_inh=False, **kwargs):\n",
    "        f = open(file_path, 'r')\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        N = 1000 # neurons \n",
    "        \n",
    "        # Read Spike Times\n",
    "        spike_times = [[]] * N\n",
    "        for line in lines:\n",
    "            sec, msec, n = line.split(' ')[:3]\n",
    "            t = float(sec)*1000. + float(msec)\n",
    "            n = int(n)\n",
    "            if t > t_stop:\n",
    "                break\n",
    "            spike_times[n] = spike_times[n] + [t]\n",
    "\n",
    "        # Fill Spike Trains\n",
    "        nbr_neurons = N\n",
    "        if filter_inh:\n",
    "            nbr_neurons = 800\n",
    "            \n",
    "        spiketrains = [[]] * nbr_neurons\n",
    "        for n, st in enumerate(spike_times):\n",
    "            if n < 800:\n",
    "                n_type = 'exc'\n",
    "            else:\n",
    "                n_type = 'inh'\n",
    "            if not filter_inh or n_type == 'exc':\n",
    "                spiketrains[n] = SpikeTrain(np.sort(st), units='ms', \n",
    "                                            t_start=t_start, t_stop=t_stop,\n",
    "                                            n_type=n_type, unitID=n)\n",
    "        return spiketrains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### For the model-to-model comparison we derive a model class for each implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C simulation\n",
    "class C_sim(polychrony_data):\n",
    "    file_path = data_path + 'C/out_firings_after5h.dat'\n",
    "    params = copy(polychrony_data.params)\n",
    "    params.update(color='#2173a3', simulator='C')\n",
    "    \n",
    "# SpiNNaker simulation    \n",
    "class S_sim(polychrony_data):\n",
    "    file_path = data_path + '/SpiNNaker/out_firings_after5h.dat'\n",
    "    params = copy(polychrony_data.params)\n",
    "    params.update(color='#77b74a', simulator='SpiNNaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = C_sim(name='C')\n",
    "S = S_sim(name='SpiNNaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Show the spiking activity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, sharex=True, \n",
    "                       gridspec_kw={'hspace':0}, \n",
    "                       figsize=(35,12))\n",
    "\n",
    "for sim_count, sim in enumerate([S, C]):\n",
    "    sim.produce_spiketrains()\n",
    "    for st_count, st in enumerate(sim.spiketrains):\n",
    "        ax[sim_count].scatter(st, [st_count]*len(st), \n",
    "                              color=sim.params['color'], \n",
    "                              marker='.', s=.5)\n",
    "        \n",
    "    ax[sim_count].set_ylabel(sim.name)\n",
    "ax[-1].set_xlabel('t [ms]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Test definitons\n",
    "The validation tests are also defined as classes. NetworkUnit offers a variety of base tests from which tests can be derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FR_test_class(sciunit.TestM2M, tests.firing_rate_test):\n",
    "    score_type = scores.effect_size\n",
    "    \n",
    "class LV_test_class(sciunit.TestM2M, tests.isi_variation_test):\n",
    "    score_type = scores.effect_size\n",
    "    params = {'variation_measure': 'lv'}\n",
    "    \n",
    "FR_test = FR_test_class()\n",
    "LV_test = LV_test_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What can tests do?\n",
    "... every test has a function generate_prediction() which calculates the test measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR_test.generate_prediction(C);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What can tests do?\n",
    "... the test classes are also able to visualize the the generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, sharey=True, gridspec_kw={'wspace':0}, figsize=(20,8))\n",
    "\n",
    "FR_test.visualize_samples(C, S, ax=ax[0], var_name='FR (Hz)', bins=30, density=False)\n",
    "LV_test.visualize_samples(C, S, ax=ax[1], var_name='LV', bins=30, density=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What can tests do? \n",
    "... to perform the actual validation and calculate a test score, you call the judge() function, which will\n",
    "    1. check if the model has all the required capabilities.\n",
    "    2. call generate_prediction()\n",
    "    3. call compute_score()\n",
    "    4. check that the score is of score_type\n",
    "    5. equip the score with metadata\n",
    "    6. returns the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# For a model-to-model test the two models are passed as a list\n",
    "print('FR test:\\n', FR_test.judge([C, S]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# to access an element of the score DataFrame use\n",
    "print('FR-Test ', FR_test.judge([C, S]).iloc[1,0])\n",
    "print('LV-Test ', LV_test.judge([C, S]).iloc[1,0])\n",
    "# print of a score instance invokes the __str__ property of the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Using a different statistical test as score type is as simple as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FR_ks_test_class(sciunit.TestM2M, tests.firing_rate_test):\n",
    "    score_type = scores.ks_distance # students_t, kl_divergence, mwu_statistic, best_effect_size, LeveneScore\n",
    "\n",
    "FR_ks_test = FR_ks_test_class()\n",
    "\n",
    "print(FR_ks_test.judge([C, S]).iloc[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### That's all good and fine but what about experimental data !?!?!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experimental data for this example is taken from [Brochier et al. (2018)](brochier2018). The provided datasets were recorded in the motor cortex of two macaque monkeys using Utah multi-electrode arrays. The underlying task was an instructed delayed reach-to-grasp task, the details of which are described in [Riehle et al. (2013)](#riehle2013) and [Brochier et al. (2018)](brochier2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Clone repository (this will not download large data files)\n",
    "!git clone git@gin.g-node.org:/doi/multielectrode_grasp.git\n",
    "\n",
    "# download large data files needed for this example\n",
    "os.chdir('./multielectrode_grasp')\n",
    "!git-annex get ./datasets/l101210-001.odml # metadata for monkey L\n",
    "!git-annex get ./datasets/l101210-001.ns2 # analog signals for monkey L\n",
    "!git-annex get ./datasets/l101210-001.ccf\n",
    "!git-annex get ./datasets/l101210-001.nev # unsorted spike times for monkey L\n",
    "!git-annex get ./datasets/l101210-001-02.nev # sorted spike times for monkey L\n",
    "!git-annex get ./datasets/i140703-001.odml # metadata for monkey I\n",
    "!git-annex get ./datasets/i140703-001.ns2 # analog signals monkey I\n",
    "!git-annex get ./datasets/i140703-001.ccf\n",
    "!git-annex get ./datasets/i140703-001.nev # unsorted spike times for monkey I\n",
    "!git-annex get ./datasets/i140703-001-03.nev # sorted spike times for monkey I\n",
    "os.chdir('..')\n",
    "\n",
    "# set data path\n",
    "download_path = \"./multielectrode_grasp/\"\n",
    "data_path = './multielectrode_grasp/datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### load the data and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!( echo \"code/reachgraspio/reachgraspio.py\" \\\n",
    "&& echo \"code/neo_utils.py\" \\\n",
    "&& echo \"datasets/l101210-001.odml\" \\\n",
    "&& echo \"datasets/l101210-001.ns2\" \\\n",
    "&& echo \"datasets/l101210-001.nev\" \\\n",
    "&& echo \"datasets/l101210-001-02.nev\" \\\n",
    "&& echo \"datasets/i140703-001.odml\" \\\n",
    "&& echo \"datasets/i140703-001.ns2\" \\\n",
    "&& echo \"datasets/i140703-001.ccf\" \\\n",
    "&& echo \"datasets/i140703-001.nev\" \\\n",
    "&& echo \"datasets/i140703-001-03.nev\") \\\n",
    "> download_files.txt\n",
    "!wget -nH -nc -r -np -e robots=off -i download_files.txt -B https://web.gin.g-node.org/doi/multielectrode_grasp/raw/master/\n",
    "download_path = \"./doi/multielectrode_grasp/raw/master/\"\n",
    "data_path = download_path + 'datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### load odml and add everything to the python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%capture\n",
    "!wget https://github.com/G-Node/python-odml/archive/version_1.2.zip\n",
    "!unzip version_1.2.zip\n",
    "os.chdir(\"./python-odml-version_1.2\")\n",
    "!python setup.py install\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, './python-odml-version_1.2')\n",
    "sys.path.extend((download_path + 'code',\n",
    "                 download_path + 'code/reachgraspio'))\n",
    "from neo_utils import add_epoch, cut_segment_by_epoch, get_events\n",
    "import reachgraspio as rgio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Define model classes as wrappers for the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exp_data(models.experimental_data, capabilities.cap_ProducesSpikeTrains.ProducesSpikeTrains):\n",
    "    \"\"\"\n",
    "    A model class to load data from reach2grasp experiment. Spike times from the\n",
    "    complete recording sessions are loaded.\n",
    "    \"\"\"\n",
    "\n",
    "    def load(self, datfile, **kwargs):\n",
    "        \"\"\"\n",
    "        Loads data from datfile.\n",
    "        \"\"\"        \n",
    "        # set paths\n",
    "        fpath = data_path + datfile\n",
    "        print('loading data from ' +fpath +'.nev')\n",
    "        print('this may take a minute..')\n",
    "        # load session and get event times\n",
    "        session = rgio.ReachGraspIO(fpath, odml_directory=data_path)\n",
    "        block = session.read_block(nsx_to_load='all', units='all', load_events=True, scaling='voltage')\n",
    "        data_segment = block.segments[0]\n",
    "        start_event = get_events(data_segment, properties={\n",
    "                'trial_event_labels': self.params['start_trigger'],\n",
    "                'performance_in_trial': session.performance_codes['correct_trial']})[0]\n",
    "        stop_event = get_events(data_segment, properties={\n",
    "                'trial_event_labels': self.params['stop_trigger'],\n",
    "                'performance_in_trial': session.performance_codes['correct_trial']})[0]\n",
    "        # select segments and get spiketrains\n",
    "        selected_trial_segments = self.select_trial_segments(data_segment, start_event, stop_event)\n",
    "        spiketrains = self.get_spiketrains(selected_trial_segments)\n",
    "        \n",
    "        return spiketrains\n",
    "    \n",
    "    \n",
    "    def select_trial_segments(self, data_segment, start_event, stop_event, **kwargs):\n",
    "        '''\n",
    "        Filters out trials from given data_segment\n",
    "        ''' \n",
    "        epoch = add_epoch(data_segment, event1=start_event, event2=stop_event, attach_result=False)        \n",
    "        cut_trial_block = neo.Block(name=\"Cut_Trials\")\n",
    "        cut_trial_block.segments = cut_segment_by_epoch(data_segment, epoch, reset_time=True)\n",
    "        selected_trial_segments = []\n",
    "        for tr_typ in self.params['trial_types']:\n",
    "            selected_trial_segments.extend(cut_trial_block.filter(targdict={'belongs_to_trialtype': tr_typ}, \n",
    "                                                                  objects=neo.Segment))\n",
    "        self.n_trials = len(selected_trial_segments)\n",
    "        self.n_units = len(selected_trial_segments[0].filter({'sua': True}))\n",
    "        return selected_trial_segments\n",
    "        \n",
    "        \n",
    "    def get_spiketrains(self, selected_trial_segments, **kwargs):\n",
    "        '''\n",
    "        Appends all spike trains in selected_trial_segments to a list\n",
    "        of spike trains. Spike trains with SNR<2.5 are sorted out.\n",
    "        '''\n",
    "        spiketrains = []\n",
    "        for seg_id, seg in enumerate(selected_trial_segments):\n",
    "            # Discarding non-valid trials\n",
    "            if seg.annotations['trial_id'] == -1:\n",
    "                continue\n",
    "            # Selecting only the SUAs\n",
    "            for st in seg.filter({'sua': True}):\n",
    "                # Check the SNR, only use units with SNR>2.5 (see Brochier et al, 2018)\n",
    "                if st.annotations['SNR'] > 2.5:\n",
    "                    st.annotations['trial_id'] = seg.annotations['trial_id']\n",
    "                    st.annotations['trial_type'] = seg.annotations['belongs_to_trialtype']\n",
    "                    st.annotate(trial_id_trialtype=seg_id)\n",
    "                    spiketrains.append(st)\n",
    "        return spiketrains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Define derived model classes for each monkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TS_ON : trial start\n",
    "\n",
    "CUE-ON : grip type signal (800ms after TS_ON)\n",
    "\n",
    "PG / SG : precision grip / side grip\n",
    "\n",
    "LF / HF : low force / high force\n",
    "\n",
    "spike trains with SNR < 2.5 are discarded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A general experimental data class is defined, which is the basis to load the two data sets into the NetworkUnit framework. For the sake of simplicity, we load all the single unit activity data within a fixed time window of 800ms ranging from 'TS_ON' to 'CUE_ON'. 'TS_ON' defines the start of the trial and 800ms later the grip type is signalled by 'CUE_ON'. This means that there is no trial type information in the given time window. The data is handed over to NetworkUnit as a list of spiketrains with n_units * n_trial elements. Spike trains are discarded if their signal to noise ration is small (SNR<2.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkey L\n",
    "class exp_class_L(exp_data):\n",
    "    datfile = 'l101210-001'\n",
    "    params = {'start_trigger': 'TS-ON',\n",
    "              'stop_trigger': 'CUE-ON',\n",
    "              'trial_types': ['PGLF', 'PGHF', 'SGLF', 'SGHF'],\n",
    "              'color': '#ff8000'\n",
    "              }\n",
    "    \n",
    "# Monkey I\n",
    "class exp_class_I(exp_data):\n",
    "    datfile = 'i140703-001'\n",
    "    params = {'start_trigger': 'TS-ON',\n",
    "              'stop_trigger': 'CUE-ON',\n",
    "              'trial_types': ['PGLF', 'PGHF', 'SGLF', 'SGHF'],\n",
    "              'color': '#9b59b6'\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = exp_class_L(name='Monkey L')\n",
    "I = exp_class_I(name='Monkey I')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Show spiking activity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, sharex=True, \n",
    "                       gridspec_kw={'hspace':0}, \n",
    "                       figsize=(35,12))\n",
    "\n",
    "for sim_count, sim in enumerate([S, C]):\n",
    "    sim.produce_spiketrains()\n",
    "    for st_count, st in enumerate(sim.spiketrains):\n",
    "        ax[sim_count].scatter(st, [st_count]*len(st), \n",
    "                              color=sim.params['color'], \n",
    "                              marker='.', s=.5)\n",
    "        \n",
    "    ax[sim_count].set_ylabel(sim.name)\n",
    "ax[-1].set_xlabel('t [ms]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We use the same tests as before to compare the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, sharey=True, gridspec_kw={'wspace':0}, figsize=(20,8))\n",
    "\n",
    "FR_test.visualize_samples(L, I, ax=ax[0], var_name='FR (Hz)', bins=30, density=False)\n",
    "LV_test.visualize_samples(L, I, ax=ax[1], var_name='LV', bins=30, density=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FR-Test ', FR_test.judge([C, S]).iloc[1,0])\n",
    "print('LV-Test ', LV_test.judge([C, S]).iloc[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation testing on the level of network activity is a useful apprach (complementary to single-cell validation) to evaluate network models\n",
    "\n",
    "#### NetworkUnit can be used to quantify the statistical difference between models and experimental data sets\n",
    "\n",
    "#### Validation testing is applicable for \n",
    "- a) comparing model predictions to experimental findings, \n",
    "- b) guiding the model development, \n",
    "- c) checking for consistency within or across models (or data sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><i>\"A model, like a novel, may resonate with nature, but it is not a 'real' thing. Like novel, a model may be convinving - it may 'ring true' if it is consistent with our experience of the natural world. But just as we may wonder how much the characters in a novel are drawn from real life and how much is artifice, we might ask the same of a model: How much is based on observation and measurement of accesssible phenomena, how much is based on informed judgment, and how much is convencience?\"</i></p>\n",
    "<p style=\"float:right\">Orsekes, 1994</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Trensch et al. (2018)  Rigorous neural network simulations: model cross-validation665for boosting the correctness of simulation results, Frontiers in Neuroinformatics. 10.3389/fninf.2018.00081<a id='trensch2018'></a>\n",
    "\n",
    "- Gutzen et al. (2018) Reproducible neural network simulations: model validation on the level of network activity data, Frontiers in Neuroinformatics, submitted<a id='gutzen2018'></a>\n",
    "\n",
    "- Schlesinger, S. (1979). Terminology for model credibility, Simulation 32, 103-104. doi: 10.1177/003754977903200304<a id='schlesinger1979'></a> \n",
    "\n",
    "- Izhikevich, E. M. (2006). Polychronization: Computation with spikes, Neural Computation 18, 245–282. doi: 10.1162/089976606775093882 <a id='izhikevich2006'></a> \n",
    "\n",
    "- Brochier et al. (2018) Massively parallel recordings in macaque motor cortex during an instructed delayed reach-to-grasp task, Scientific Data, 5, pp. 1–23. doi: 10.1038/sdata.2018.55. <a id='brochier2018'></a> \n",
    "\n",
    "- Riehle et al. (2013) Mapping the spatio-temporal structure of motor cortical LFP and spiking activities during reach-to-grasp movements, Frontiers in Neural Circuits, 7(48). doi: 10.3389/fncir.2013.00048. <a id='riehle2013'></a> \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "livereveal": {
   "autolaunch": true,
   "scroll": true
  },
  "rise": {
   "autolaunch": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
