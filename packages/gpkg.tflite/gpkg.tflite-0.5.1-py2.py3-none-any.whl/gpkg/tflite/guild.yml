# Copyright 2018 TensorHub, Inc. and contributors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# ===================================================================
# Package def
# ===================================================================

- package: gpkg.tflite
  version: 0.5.1
  description: TensorFlow Lite support (Guild AI)
  url: https://github.com/guildai/packages/tree/master/gpkg/tflite
  author: Guild AI
  author-email: packages@guild.ai
  license: Apache 2.0

# ===================================================================
# TF Lite support
# ===================================================================

- config: tflite-support
  params:
    frozen-graph-path: frozen_inference_graph.pb
    tflite-output-path: model.tflite
    tflite-input-layers: '{{input-layer}}'
    tflite-input-shapes: ''
    tflite-output-layers: '{{output-layer}}'
  operations:
    tflite:
      description: Generate a TFLite file from a frozen graph
      main:
        tensorflow/contrib/lite/python/tflite_convert
          --graph_def_file {{frozen-graph-path}}
          --output_file {{tflite-output-path}}
          --input_arrays {{tflite-input-layers}}
          --input_shapes '{{tflite-input-shapes}}'
          --output_arrays {{tflite-output-layers}}
          --allow_custom_ops
      requires:
        - frozen-graph
      label-template: graph=${frozen-graph}
      flags:
        quantized:
          description: Whether or not output arrays are quantized
          choices:
            - value: yes
              args:
                inference_type: quantized_uint8
            - value: no
              args:
                inference_type: float
          default: no
          arg-skip: yes
        quantized-inputs:
          description: Whether or not input arrays are quantized
          choices:
            - value: yes
              args:
                inference_input_type: quantized_uint8
            - value: no
              args:
                inference_input_type: float
          default: no
          arg-skip: yes
        output-format:
          description: TF Lite output format
          choices:
            - tflite
            - graphviz_dot
          default: tflite



#[--input_arrays INPUT_ARRAYS]
#[--input_shapes INPUT_SHAPES]
#[--output_arrays OUTPUT_ARRAYS]

#[--saved_model_tag_set SAVED_MODEL_TAG_SET]
#[--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY]
#[--std_dev_values STD_DEV_VALUES]
#[--mean_values MEAN_VALUES]
#[--default_ranges_min DEFAULT_RANGES_MIN]
#[--default_ranges_max DEFAULT_RANGES_MAX]
#[--post_training_quantize]
#[--drop_control_dependency]
#[--reorder_across_fake_quant]
#[--change_concat_input_ranges {TRUE,FALSE}]
#[--allow_custom_ops]
#[--dump_graphviz_dir DUMP_GRAPHVIZ_DIR]
#[--dump_graphviz_video]
